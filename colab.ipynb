{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/google/applied-machine-learning-intensive/blob/master/content/04_classification/03_classification_with_tensorflow/colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "copyright"
   },
   "source": [
    "#### Copyright 2020 Google LLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BX4BkCSEPV26"
   },
   "outputs": [],
   "source": [
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eXugJRE9PcpT"
   },
   "source": [
    "# Classification with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KrDw3-6MIhhJ"
   },
   "source": [
    "By now you should be familiar with classification in scikit-learn. In this Colab we will explore another commonly used tool for classification and machine learning: TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ryWbLSCgKGOp"
   },
   "source": [
    "## The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "owzuGnZ9KH57"
   },
   "source": [
    "The dataset that we'll be using is the [UCI Heart Disease dataset](http://archive.ics.uci.edu/ml/datasets/Heart+Disease). The dataset contains health information about patients, as well as a \"presence of heart disease\" indicator.\n",
    "\n",
    "The [original dataset](http://archive.ics.uci.edu/ml/datasets/Heart+Disease) contains over 70 different attributes and five heart disease classifications. For this lab we'll use a [simplified version of the dataset](https://www.kaggle.com/ronitf/heart-disease-uci) hosted on Kaggle.\n",
    "\n",
    "This simplified version of the dataset contains 13 attributes and a yes/no indicator for the presence or absence of heart disease.\n",
    "\n",
    "The columns are below:\n",
    "\n",
    "Feature | Description\n",
    "--------|--------------\n",
    "age     | age in years\n",
    "sex     | sex<br>0 = female<br>1 = male\n",
    "cp      | chest pain type<br>1 = typical angina<br>2 = atypical angina<br>3 = non-anginal pain<br>4 = asymptomatic\n",
    "trestbps  | resting blood pressure in Hg\n",
    "chol      | serum cholesterol in mg/dl\n",
    "fbs       | is fasting blood sugar > 120 mg/dl<br>0 = false<br>1 = true\n",
    "restecg   | results of a resting electrocardiograph<br>0 = normal<br>1 = ST-T wave abnormality<br>2 = left ventricular hypertrophy\n",
    "thalach   | max heart rate\n",
    "exang     | exercise induced angina<br>0 = no<br>1 = yes\n",
    "oldpeak   | measurement of an abnormal ST depression\n",
    "slope     | slope of peak of exercise ST segment<br>1 = upslope<br>2 = flat<br>3 = downslope\n",
    "ca        | count of major blood vessels colored by fluoroscopy<br>0, 1, 2, 3, or 4\n",
    "thal      | presence heart condition<br>0 = unknown<br>1 = normal<br>2 = fixed defect<br>3 = reversible defect\n",
    "\n",
    "The heart disease indicator is a 0 for no disease and a 1 for heart disease.\n",
    "\n",
    "Let's assume we have been given this dataset by the Cleveland Clinic and have been asked to build a model that can predict if their patients have heart disease or not. The purpose of the model is to assist doctors in making diagnostic decisions faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Ci8tyuGL365"
   },
   "source": [
    "### Exercise 1: Ethical Considerations\n",
    "\n",
    "Before we dive in, let's take a moment to think about the dataset and the larger problem that we are trying to solve. We have 17 data attributes related to an individual's health, as well as an indicator that determines if the patient has heart disease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fNn5FTmaMEux"
   },
   "source": [
    "#### Question 1\n",
    "\n",
    "Are there any attributes in the data that we should pay special attention to? Imagine a case where the data is unbalanced in some way. How might that affect the model and the doctor/patient experience?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f7SNDV81NkHV"
   },
   "source": [
    "##### **Student Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tEfCxyNVNlk_"
   },
   "source": [
    "> *Your answer goes here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zNemvB8nTjz-"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xBAYBKo-Ozja"
   },
   "source": [
    "#### Question 2\n",
    "\n",
    "Assuming we can get a reasonably well-performing model deployed, is there potential for problems with how the predictions from this model are interpreted and used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_IriIC2DPL8d"
   },
   "source": [
    "##### **Student Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PhRc5qbjPNn2"
   },
   "source": [
    "> *Your answer goes here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KU1bmHjCTsKH"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "70JOzTBLPwcf"
   },
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t-igE14mP0X5"
   },
   "source": [
    "Let's download the data and take a look at what we are working with.\n",
    "\n",
    "Upload your `kaggle.json` file and run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gNulecG9as1b"
   },
   "outputs": [],
   "source": [
    "! chmod 600 kaggle.json && (ls ~/.kaggle 2>/dev/null || mkdir ~/.kaggle) && mv kaggle.json ~/.kaggle/ && echo 'Done'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_My-5RPAP9qC"
   },
   "source": [
    "And then download the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kj7CvPiWbPP7"
   },
   "outputs": [],
   "source": [
    "!kaggle datasets download ronitf/heart-disease-uci\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7_An5CMFQBFJ"
   },
   "source": [
    "And load the data into a `DataFrame` and take a peek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yBFg4O0TbSTX"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('heart-disease-uci.zip')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lg3B3HXYQOEF"
   },
   "source": [
    "We can see that all of the data is numeric, but varies a bit in scale.\n",
    "\n",
    "Let's describe the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tFod1RMIbZar"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HePmoUX8QZ68"
   },
   "source": [
    "No missing data. Only 303 rows of data, though, so we aren't working with a huge dataset.\n",
    "\n",
    "Now we'll dig deeper into the data in a few of the columns. If you were working with a dataset for a real-world model you would want to explore each column.\n",
    "\n",
    "We'll start by mapping out the correlations in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2zpT6H3IQzlV"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "_ = sns.heatmap(df.corr(), cmap='coolwarm', annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YuYIA8KFRich"
   },
   "source": [
    "There are no obviously strong correlations.\n",
    "\n",
    "Let's now see how balanced our data is by sex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HhNIowgiRrV_"
   },
   "outputs": [],
   "source": [
    "df['sex'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MQAIX7B_Ry51"
   },
   "source": [
    "In this data female maps to 0 and male maps to 1, so there are over twice as many men in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xUCv_seER_QL"
   },
   "source": [
    "Let's also check out the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dtw_Qi1ER8fo"
   },
   "outputs": [],
   "source": [
    "df['target'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nRJWasBGSC_j"
   },
   "source": [
    "In this case the dataset looks more balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ejVlvHCqSLJK"
   },
   "source": [
    "And finally we'll look at age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zWaUmlctSHZx"
   },
   "outputs": [],
   "source": [
    "df['age'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K105PK38SPou"
   },
   "source": [
    "The dataset seems to be pretty heavily skewed toward individuals in their 50s and 60s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dSxDdJ1QSezo"
   },
   "source": [
    "There isn't a lot of actionable information from our analysis. We might want to stratify our data by sex when we train and test our model, but there are no data repairs that seem to need to be done.\n",
    "\n",
    "If you were building this model for a real world application, you would also want to ensure that the values in the numeric columns are realistic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GzJm-2mScy-"
   },
   "source": [
    "## The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "istg6urgS-Ke"
   },
   "source": [
    "Let's build and train our model. We'll build a deep neural network that takes our input features and returns a `0` if it predicts that the patient doesn't have heart disease and a `1` if it predicts that the patient does have heart disease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3QM9AMMYTbQ7"
   },
   "source": [
    "First let's create a list of features to make coding easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0J_mhetHTn2s"
   },
   "outputs": [],
   "source": [
    "FEATURES = df.columns.values[:-1]\n",
    "TARGET = df.columns.values[-1]\n",
    "\n",
    "FEATURES, TARGET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nZSZ94RVTrHv"
   },
   "source": [
    "We'll also want to normalize our feature data before feeding it into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y3o_nvShTwKE"
   },
   "outputs": [],
   "source": [
    "df.loc[:, FEATURES] = ((df[FEATURES] - df[FEATURES].min()) / (df[FEATURES].max() - df[FEATURES].min()))\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TCtMxC49Ubev"
   },
   "source": [
    "We can also now split off a validation set from our data. Since we have so many more men than women in this dataset, we will stratify on sex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "putOqS6YUnu8"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(\n",
    "    df[FEATURES], df[TARGET], test_size=0.2, stratify=df['sex'])\n",
    "\n",
    "X_train.shape, X_validate.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aEFNqxYjUF5h"
   },
   "source": [
    "We'll use the TensorFlow Keras [`Sequential`](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) model. The input size needs to be equal to the number of input features that we have. The output size needs to be 1 since we are predicting a yes/no value. The number and width of layers in between are an area for experimentation, as are the activation functions.\n",
    "\n",
    "We start with an initial hidden layer 64 nodes wide and funnel down to 32, 16, and finally, to the output layer of 1 node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pnxd91YdczCy"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation=tf.nn.relu, \n",
    "                          input_shape=(FEATURES.size,)),\n",
    "    tf.keras.layers.Dense(32, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(16, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9ZZ6VUxUVhB9"
   },
   "source": [
    "We can now compile the model. We use 'binary_crossentropy' loss since this is a binary classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "adzz7_VFdFUk"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='Adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xE88mejaWUxt"
   },
   "source": [
    "And finally, we can actually fit the model. We'll start with a run of 500 training epochs. Once we are done, we'll print out the final accuracy the model achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vdgB9wUmdL7V"
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=500, verbose=0)\n",
    "\n",
    "history.history['accuracy'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qIA62vjfYSa0"
   },
   "source": [
    "We got perfect accuracy in our model. Let's see how the accuracy improves and the loss is reduced over epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b7s1zaQGdkB9"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(16,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('Training Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_accuracy'], loc='best')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Training Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss'], loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "39zlRVRcZKx7"
   },
   "source": [
    "We seem to have kept training this model far too long. The accuracy reaches perfection, and the loss moves to 0.0 after a few hundred epochs.\n",
    "\n",
    "Let's see if we overfit by using our validation holdout data. In order to do that, we need to convert our predictions back into a binary representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "niAa2Ht5eAv-"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_validate)\n",
    "\n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WNTZk3TNeGVM"
   },
   "source": [
    "As you can see, our predictions are continuous numbers, not the 1 or 0 values that we expected. These values are confidences that the value is 1. Let's look at them in a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AmVuqYMReQcC"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_ = plt.hist(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "29C09tpneiYA"
   },
   "source": [
    "Here we can see that the model is highly confident yes or no in many cases, but there are some cases where the model was unsure.\n",
    "\n",
    "How do we convert these confidences into a yes/no decision?\n",
    "\n",
    "One way is to simply round:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FWlYXJ5eZehL"
   },
   "outputs": [],
   "source": [
    "predictions = [round(x[0]) for x in predictions]\n",
    "\n",
    "_ = plt.hist(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IQAe7L4-fHGO"
   },
   "source": [
    "This puts the cut-off threshold for a yes/no decision at `0.5`. Let's think about the implications of this.\n",
    "\n",
    "Also note that the choice of a sigmoid activation function was not coincidence. We wanted to use an activation function that would keep the output values between 0.0 and 1.0 for rounding purposes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YSWvcpaajd3C"
   },
   "source": [
    "Now let's check our accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XtIiFjG8jf2E"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_validate, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bXQc1DN3j4g9"
   },
   "source": [
    "When we ran this model, our score was in the low 80s, which is not great. Yours is likely similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HCZ4RNimfRu3"
   },
   "source": [
    "### Exercise 2: Adjusting the Threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X4BMDjAlgimq"
   },
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7KxSRGj3fZOS"
   },
   "source": [
    "We decided to round for our classification, which puts the threshold for the decision at `0.5`. This decision was made somewhat arbitrarily. Let's think about our problem space a bit more. We are making a model that predicts if an individual has heart disease. Would it be better if we set the threshold for predicting heart disease higher or lower than `0.5`? Or is `0.5` okay? Explain your reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CzprK-6Bglmu"
   },
   "source": [
    "##### **Student Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GYXoRF3mgrGl"
   },
   "source": [
    "> *Your solution goes here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3pv-ZufdV_yw"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Up7wa9Kvhfy1"
   },
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5ae6h-pZhzNF"
   },
   "source": [
    "Write code to make yes/no predictions using a higher or lower threshold based on the argument you made in the first question of this exercise. If you chose to keep the threshold at `0.5`, then just pick higher or lower and write the code for that. Print out the accuracy for the new threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "037j13priQpi"
   },
   "source": [
    "##### **Student Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i_Qup9sHiThc"
   },
   "outputs": [],
   "source": [
    "# Your Code Goes Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ge8XT0nUWcRf"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kltnsr4Udquq"
   },
   "source": [
    "### Exercise 2: Early Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MGImZmxAkBIz"
   },
   "source": [
    "Five hundred epochs turned out to be a bit too many. Use the [`EarlyStopping`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) class to stop when the loss doesn't improve over the course of five epochs. Print your accuracy score so you can see if it stayed reasonably close to your earlier model. Be sure to also make model fitting verbosity 1 or 2 so you can see at which epoch your model stopped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U_MG9C-tlMOX"
   },
   "source": [
    "##### **Student Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0w2rGyG4lOQY"
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_K0Glj08Wf96"
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "copyright",
    "PcoLpQIGNn_i",
    "5du8Nf50PP_e",
    "PpuEAl0mgttU",
    "pBTMpUv0lPiY"
   ],
   "include_colab_link": true,
   "name": "Classification with TensorFlow",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
